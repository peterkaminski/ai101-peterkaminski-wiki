# AI 101 Live Session, 2024-02-22

YouTube: <https://youtu.be/9zOCZZaAwY8>

Recorded live AI Salon / AI 101 session on AI topics.

**Next:** [[AI 101 Live Session, 2024-02-23]]

**Previous:** [[AI 101 Live Session, 2024-02-17]]

## AI Summary (hopefully useful, may be inaccurate)

### Quick Recap

Pete discussed the process of installing and listing something on a website, emphasizing the functionality of the site's AI summary feature. He announced plans to expand the site's topics and connect them, as well as to post interesting information and potentially move some resources to the site. He mentioned his intention to conduct sessions where participants can check off these building blocks on their own computers and further discussed the concept of virtualization and its usefulness for AI applications.
### Summary

**Website Functionality and Expansion Plans** 

Pete discussed the process of installing and listing something on a website, emphasizing the functionality of the site's AI summary feature. He announced plans to expand the site's topics and connect them, as well as to post interesting information and potentially move some resources to the site. He mentioned his intention to conduct sessions where participants can check off these building blocks on their own computers and further discussed the concept of virtualization and its usefulness for AI applications. 

**Virtualization and AI Interface Discussion** 

Pete discussed the use and benefits of a virtualization platform called Virtual Buddy. He explained how it operates as an app and can be used for collaboration. He also mentioned the importance of using Gpd 4 instead of Gp 3.5 for specific tasks, stating that while Gp 3.5 works for 80% of tasks, Gpd 4 offers additional intelligence for the remaining 20%. Pete also mentioned the possibility of using an alternative interface for Chat Gbt Plus and the idea of setting up a glossary for AI-related terms. However, he encountered some technical issues with the platform during the meeting. 

**CFG Tool and Metaphors in Computer Science** 

Pete introduced a tool called Cfg and its features, while Daniele showed interest in learning about the tool's terminology and compatibility with her computer. There were concerns raised about potential performance issues on older machines, which Pete acknowledged but did not clarify. The discussion also touched on the use of metaphors in computer science, with Pete explaining the concept of 'temperature' and its adaptation in computer science. No specific decisions or action items were identified in this segment of the meeting. 

**Chaos in Generative AI and Markdown's Potential** 

Pete discussed the concept of "chaos" in generative AI, explaining how it affects the unpredictability of results. He introduced the potential use of Markdown, a text-based formatting system, to guide AI bots' writing style and structure text. Pete also mentioned the limitations of AI's reasoning capabilities and the importance of structuring a curriculum to improve its effectiveness. Towards the end, the conversation shifted towards AI's emergent capabilities and its potential applications in dialogue management systems. 

**Model Functionality and AI Systems Discussion** 

The team discussed the functionality of a model, likely Gpt. 4, and its use of a mixture of experts to predict results. Pete clarified that the model, trained on specific data, provides the most statistically accurate answer and its temperature setting affects its creativity and accuracy. They also emphasized the model's ability to understand user context and handle prompts. Pete further explained the concept of a model in AI systems, likening it to the brain of the system, and the ability to switch between two different brains on OpenAI's ChatGPT. The discussion concluded with a question from Claire about the similarity between a model and an algorithm, to which Pete responded negatively. 

**Tokenization and Machine Learning Explanation** 

Pete explained the concept of tokens and their role in their operations, describing them as chunks of words with varying values across platforms. He used a car engine analogy to describe the tokenizer's importance and demonstrated how their system handles long words. The discussion also covered the inner workings of tokenization and machine learning models, with Pete explaining how these models are trained using billions of tokens to recognize patterns and make predictions. R added that these models use matrix algebra and require a GPU, and clarified that they predict based on their training, not like a person or a dog. Daniele and Dr. participated in the discussion by asking questions. 

**AI Image Generation Discussion** 

Pete and Daniele discussed the adaptive and conversational nature of an artificial intelligence system. They explored the difficulties of prompting an AI system to generate specific types of images, and the concept of negative prompts. They also discussed the functionality of an image generator program called Drawings, focusing on its stability diffusion feature. The challenges of training image generators to respond accurately to prompts were discussed, with Daniele suggesting strategies such as asking the program to clarify its outputs. The conversation concluded with Pete suggesting that the problem might be related to the prompts, rather than the program's ability to process them. 

**Experimenting With AI Image Generation Tools** 

The team discussed the use of AI tools, particularly Chat GPT, for generating images and prompts. They explored the idea of telling the AI what kind of image they want it to create, and then asking it to write the prompt for that image. They also considered reusing prompts and the potential for the AI to misinterpret the prompts. There were some difficulties with the AI creating images that didn't match the descriptions, such as a man with a perfectly smooth face having a beard. The team agreed to continue experimenting with the tool to better understand its capabilities.

